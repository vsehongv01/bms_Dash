import requests
import sys
import pandas as pd
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from datetime import datetime, timedelta
import time
import os
import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

# ==========================================
# [ì„¤ì • êµ¬ê°„]
# ==========================================
COOKIE = "connect.sid=s%3AUVy2iaeTlYD_7JsxXi0APfnYvsfuTC_T.%2BBpwa59U7ON9nBA%2F8x9yUcX7bOxIxpoW351Pe%2F54kgQ"
STORE_ID = 12
SPREADSHEET_NAME = "BMS_Dashboard_Data"
# ==========================================

HEADERS = {"Content-Type": "application/json", "User-Agent": "Mozilla/5.0"}
COOKIES = {"connect.sid": COOKIE.split('=')[-1]}

def get_google_sheet():
    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
    # ì ˆëŒ€ ê²½ë¡œë¡œ credentials.json ìœ„ì¹˜ ì°¾ê¸° (FileNotFoundError í•´ê²°)
    base_dir = os.path.dirname(os.path.abspath(__file__))
    credentials_path = os.path.join(base_dir, 'credentials.json')
    
    creds = ServiceAccountCredentials.from_json_keyfile_name(credentials_path, scope)
    client = gspread.authorize(creds)
    return client.open(SPREADSHEET_NAME).get_worksheet(0)

def fetch_full_data(start_date):
    end_date = datetime.now().strftime("%Y-%m-%d")
    url_list = "https://bmsapi.breezm.com/order/list"
    payload = {"storeIds": [STORE_ID], "startDate": start_date, "endDate": end_date}
    
    print(f"ğŸš€ {start_date} ~ {end_date} ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
    try:
        res = requests.post(url_list, json=payload, headers=HEADERS, cookies=COOKIES)
        if res.status_code not in [200, 201]:
            print(f"âŒ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨ (Status: {res.status_code})")
            print(f"ğŸ‘‰ ì¿ í‚¤ê°€ ë§Œë£Œë˜ì—ˆê±°ë‚˜ ê¶Œí•œì´ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (Response: {res.text[:100]})")
            return pd.DataFrame()
        order_list = res.json()
    except Exception as e:
        print(f"âŒ API ìš”ì²­ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame()
    
    all_rows = []
    total = len(order_list)
    
    for i, item in enumerate(order_list):
        oid = item['id']
        print(f"PROGRESS: {i+1}/{total}")
        print(f"[{i+1}/{total}] ëª¨ë“  ìƒì„¸ ì •ë³´ ì¶”ì¶œ ì¤‘: {item['code']}")
        sys.stdout.flush()
        
        try:
            detail_res = requests.get(f"https://bmsapi.breezm.com/order/{oid}/detail", headers=HEADERS, cookies=COOKIES)
            if detail_res.status_code != 200:
                 print(f"âš ï¸ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨ ({oid}): {detail_res.status_code}")
                 continue
            d = detail_res.json()
            
            # [ì›ë˜ ì˜ë„ ìœ ì§€] json_normalize ì‚¬ìš©í•˜ì—¬ ì „ì²´ ë°ì´í„° í”Œë«í™”
            flat_data = pd.json_normalize(d)
            all_rows.append(flat_data)
            
            time.sleep(0.05)
        except Exception as e:
            print(f"âŒ {item['code']} ì‹¤íŒ¨: {e}")
            
    # ë¹ˆ ë°ì´í„°í”„ë ˆì„ ì œê±° ë° ë³‘í•© (FutureWarning í•´ê²°)
    valid_rows = [df for df in all_rows if not df.empty]
    
    if not valid_rows:
        return pd.DataFrame()
        
    return pd.concat(valid_rows, ignore_index=True)

def sync_to_google(new_df):
    sheet = get_google_sheet()
    
    # 1. ë¦¬ìŠ¤íŠ¸ ë° ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ê³  ê¸€ì ìˆ˜ ì œí•œ(30,000ì) ê±¸ê¸°
    def clean_cell(x):
        if isinstance(x, (list, dict)): val = str(x)
        else: val = x
        if isinstance(val, str) and len(val) > 30000:
            return val[:30000] + "...(ì¤‘ëµ)"
        return val

    # ëª¨ë“  ì…€ì— ëŒ€í•´ í´ë¦¬ë‹ ì‘ì—… ìˆ˜í–‰
    for col in new_df.columns:
        new_df[col] = new_df[col].apply(clean_cell)

    # 2. NaN(ë¹ˆê°’) ì²˜ë¦¬
    new_df = new_df.fillna("")
    
    # 3. ê¸°ì¡´ ë°ì´í„°ì™€ í•©ì¹˜ê¸°
    try:
        rows = sheet.get_all_records()
        if rows:
            existing_df = pd.DataFrame(rows)
            # FutureWarning ë°©ì§€: ë°ì´í„°ê°€ ìˆëŠ” ê²ƒë“¤ë§Œ í•©ì¹¨. drop_duplicatesëŠ” code ê¸°ì¤€
            combined_df = pd.concat([existing_df, new_df]).drop_duplicates(subset=['code'], keep='last')
        else:
            combined_df = new_df
    except:
        combined_df = new_df

    combined_df = combined_df.fillna("")

    # 4. ë°ì´í„° ì „ì†¡ (ë¶„í•  ì „ì†¡ ì ìš©)
    data_to_update = [combined_df.columns.values.tolist()] + combined_df.values.tolist()
    
    try:
        sheet.clear()
        print("\nğŸ§¹ êµ¬ê¸€ ì‹œíŠ¸ ì´ˆê¸°í™” ì™„ë£Œ. ë„ˆë¬´ ë§ì€ ë°ì´í„°ë¼ 1000ê°œì”© ìª¼ê°œì„œ ì „ì†¡í•©ë‹ˆë‹¤...")
        
        # í—¤ë”(ì²« ì¤„) ë¨¼ì € ì—…ë°ì´íŠ¸
        # gspread ë²„ì „ì— ë”°ë¼ kwargs í˜¸í™˜ì„± ê³ ë ¤
        sheet.update(values=[data_to_update[0]], range_name="A1")
        
        chunk_size = 1000 # 1000ì¤„ì”© ìª¼ê°œê¸°
        row_idx = 2       # ë‘ ë²ˆì§¸ ì¤„ë¶€í„° ë°ì´í„° ì‹œì‘
        
        for i in range(1, len(data_to_update), chunk_size):
            chunk = data_to_update[i : i + chunk_size]
            start_cell = f"A{row_idx}"
            
            # gspread ë²„ì „ì— ìƒê´€ì—†ì´ ì‘ë™í•˜ë„ë¡ kwargs ì‚¬ìš©
            sheet.update(values=chunk, range_name=start_cell)
            
            print(f"ğŸ“¦ {i} ~ {i + len(chunk) - 1}ë²ˆì§¸ ì¤„ ì „ì†¡ ì™„ë£Œ")
            row_idx += len(chunk)
            
            # êµ¬ê¸€ ì„œë²„ê°€ ìˆ¨ ì‰´ í‹ˆ(1.5ì´ˆ) ì£¼ê¸° (API ê³¼ë¶€í•˜ ë°©ì§€)
            time.sleep(1.5) 
            
        print(f"\nâœ… ë™ê¸°í™” ì™„ë£Œ! ì´ {len(combined_df)}ê±´ì˜ ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        print(f"âŒ ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


if __name__ == "__main__":
    # ëª…ë ¹í–‰ ì¸ìê°€ ìˆìœ¼ë©´ ìë™ ì‹¤í–‰ (ëŒ€ì‹œë³´ë“œì—ì„œ í˜¸ì¶œìš©)
    if len(sys.argv) > 1:
        mode = sys.argv[1]
        
        if mode == "1week":
            start_date = (datetime.now() - timedelta(days=7)).strftime("%Y-%m-%d")
            print(f"ğŸ”„ ìµœê·¼ 1ì£¼ì¼ ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œì‘ ({start_date} ~)")
        elif mode == "3months":
            start_date = (datetime.now() - timedelta(days=90)).strftime("%Y-%m-%d")
            print(f"ğŸ”„ ìµœê·¼ 3ê°œì›” ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œì‘ ({start_date} ~)")
        elif mode == "all":
            start_date = "2024-08-01"
            print(f"ğŸ”„ ì „ì²´ ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œì‘ ({start_date} ~)")
        else:
            print("âŒ ì˜ëª»ëœ ëª¨ë“œì…ë‹ˆë‹¤. (1week, 3months, all ì¤‘ ì„ íƒ)")
            sys.exit(1)
            
        df = fetch_full_data(start_date)
        if not df.empty:
            sync_to_google(df)
            
    # ì¸ìê°€ ì—†ìœ¼ë©´ ëŒ€í™”í˜• ëª¨ë“œ (ê¸°ì¡´ ë°©ì‹)
    else:
        print("1. ìµœê·¼ë°ì´í„°(3ë‹¬) 2. ì „ì²´ë°ì´í„°(2024-08-01) 3. ìµœê·¼ 1ì£¼ì¼")
        choice = input("ì„ íƒ: ")
        
        if choice == '1':
            start = (datetime.now() - timedelta(days=90)).strftime("%Y-%m-%d")
        elif choice == '2':
            start = "2024-08-01"
        elif choice == '3':
            start = (datetime.now() - timedelta(days=7)).strftime("%Y-%m-%d")
        else:
            print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
            sys.exit(1)
        
        df = fetch_full_data(start)
        if not df.empty:
            sync_to_google(df)